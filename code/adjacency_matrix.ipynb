{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to generate adjacency matrices of our scripts in the juliet dataset to be used as input for our neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "from preprocess_code import *\n",
    "data = pd.read_csv(\"../data/buffer_overflow_data.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_edge_list1(testcase, **kwargs):\n",
    "    \"\"\"\n",
    "    Takes in a list of files/datapoints from juliet.csv.zip \n",
    "    or (as loaded with pandas) matching one particulartestcase, \n",
    "    and returns an edge list of its graph representation.\n",
    "    \"\"\"\n",
    "    parse_list = [\n",
    "        (datapoint.filename, datapoint.code)\n",
    "        for datapoint in testcase.itertuples()\n",
    "    ]\n",
    "\n",
    "    primary = find_primary_source_file(testcase)\n",
    "\n",
    "    # Parse the source code with clang, and get out an ast:\n",
    "    index = clang.cindex.Index.create()\n",
    "    translation_unit = index.parse(\n",
    "        path=primary.filename,\n",
    "        unsaved_files=parse_list,\n",
    "    )\n",
    "    ast_root = translation_unit.cursor\n",
    "\n",
    "    # Memoise/concretise the ast so that we can consistently\n",
    "    # modify it, then number each node in the tree uniquely.\n",
    "    concretise_ast(ast_root)\n",
    "    number_ast_nodes(ast_root)\n",
    "\n",
    "    # Next, construct an edge list for the graph2vec input:\n",
    "    edgelist = generate_edgelist(ast_root)\n",
    "    \n",
    "    edgelist_representation = {\n",
    "        \"edges\": edgelist,\n",
    "    }\n",
    "\n",
    "    # Explicitly delete clang objects\n",
    "    del translation_unit\n",
    "    del ast_root\n",
    "    del index\n",
    "\n",
    "    return json.dumps(edgelist_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dask_data = dd.from_pandas(data, npartitions=20)\n",
    "\n",
    "# generate the graphs for all the testcases in the dataset \n",
    "\n",
    "graphs = data.groupby(['testcase_ID']).apply(\n",
    "        generate_edge_list1,\n",
    "        axis='columns',\n",
    "        meta=('generate_edge_list', 'unicode'),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_adj_matrix1(testcase):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes in a list of files/datapoints from buffer_overflow_data.csv.gz \n",
    "    matching one particular testcase, and generates an adjacency matrix \n",
    "    from the edgelist created.\n",
    "    \"\"\"\n",
    "    \n",
    "    # extracting the list of edges \n",
    "\n",
    "    x = testcase.split('edges\": ')\n",
    "    x = x[1].split('}')\n",
    "    x = ast.literal_eval(x[0])\n",
    "    \n",
    "#     return x\n",
    "\n",
    "    # generating the matrix\n",
    "    \n",
    "    G = nx.Graph()\n",
    "\n",
    "    G.add_edges_from(x)\n",
    "\n",
    "    A = nx.adjacency_matrix(G)\n",
    "\n",
    "    B = A.todense()\n",
    "\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe containing the testcase ID and its adjacency matrix \n",
    "adjacency_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_df['testcase_ID'] = data.testcase_ID.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel dies when there are more than 200 datapoints\n",
    "\n",
    "# adj_matrices = graphs.apply(gen_adj_matrix1, meta = ('generate_adj_matrices', 'O'))\n",
    "adj_matrices = graphs.apply(gen_adj_matrix1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adj_matrices = pd.DataFrame(adj_matrices)\n",
    "adj_matrices = adj_matrices.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: in a DASK framework reset_index is not a recognized function like pandas, fix this bug\n",
    "\n",
    "# adj_matrices = adj_matrices.compute()\n",
    "adj_matrices = adj_matrices.reset_index(level='testcase_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adjacency_df['adj_matrix'] = adj_matrices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_df = adjacency_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_df.to_csv(\"../data/adj_df.csv.gz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
