{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "baseline-model-binary-adj-matrices.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WD7BVc9Bk8jQ"
      },
      "source": [
        "(Uncompleted) Notebook for training and testing the baseline neural network model using adjacency matrices of the AST format of the buffer overflow datapoints. In order for the matrices to be fed into the neural network, they must all be of the same dimensions. We currently pick a subset of the data with small-ish AST matrices (614x614)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K4oesAZzmRhL"
      },
      "source": [
        "# Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W3hzFsJWtCn-",
        "outputId": "dd25bdcb-b639-4c32-a11c-75007a583f22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!mkdir -p /project/data && cd /project/data && wget -O adj.pickle https://github.com/dj311/uob-summer-project/raw/master/data/adj.pickle\n",
        "!mkdir -p /project/data && cd /project/data && wget -O buffer_overflow_data.csv.gz https://github.com/dj311/uob-summer-project/raw/master/data/buffer_overflow_data.csv.gz\n",
        "!mkdir -p /project/data && cd /project/data && wget -O adjacency-matrix-model-binary.pickle https://github.com/dj311/uob-summer-project/raw/master/data/adjacency-matrix-model-binary.pickle\n",
        "!mkdir -p /project/data && cd /project/data && wget -O feature_matrix.pickle https://github.com/dj311/uob-summer-project/raw/master/data/feature_matrix.pickle\n",
        "!mkdir -p /project/code\n",
        "%cd /project/code"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-30 13:48:39--  https://github.com/dj311/uob-summer-project/raw/master/data/adj.pickle\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/dj311/uob-summer-project/master/data/adj.pickle [following]\n",
            "--2019-07-30 13:48:44--  https://media.githubusercontent.com/media/dj311/uob-summer-project/master/data/adj.pickle\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1320521199 (1.2G) [application/octet-stream]\n",
            "Saving to: ‘adj.pickle’\n",
            "\n",
            "adj.pickle          100%[===================>]   1.23G   149MB/s    in 9.6s    \n",
            "\n",
            "2019-07-30 13:49:07 (131 MB/s) - ‘adj.pickle’ saved [1320521199/1320521199]\n",
            "\n",
            "--2019-07-30 13:49:08--  https://github.com/dj311/uob-summer-project/raw/master/data/buffer_overflow_data.csv.gz\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/dj311/uob-summer-project/master/data/buffer_overflow_data.csv.gz [following]\n",
            "--2019-07-30 13:49:08--  https://media.githubusercontent.com/media/dj311/uob-summer-project/master/data/buffer_overflow_data.csv.gz\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3008729 (2.9M) [application/octet-stream]\n",
            "Saving to: ‘buffer_overflow_data.csv.gz’\n",
            "\n",
            "buffer_overflow_dat 100%[===================>]   2.87M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2019-07-30 13:49:08 (35.3 MB/s) - ‘buffer_overflow_data.csv.gz’ saved [3008729/3008729]\n",
            "\n",
            "--2019-07-30 13:49:09--  https://github.com/dj311/uob-summer-project/raw/master/data/adjacency-matrix-model-binary.pickle\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/dj311/uob-summer-project/master/data/adjacency-matrix-model-binary.pickle [following]\n",
            "--2019-07-30 13:49:09--  https://media.githubusercontent.com/media/dj311/uob-summer-project/master/data/adjacency-matrix-model-binary.pickle\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 71124065 (68M) [application/octet-stream]\n",
            "Saving to: ‘adjacency-matrix-model-binary.pickle’\n",
            "\n",
            "adjacency-matrix-mo 100%[===================>]  67.83M   200MB/s    in 0.3s    \n",
            "\n",
            "2019-07-30 13:49:11 (200 MB/s) - ‘adjacency-matrix-model-binary.pickle’ saved [71124065/71124065]\n",
            "\n",
            "--2019-07-30 13:49:11--  https://github.com/dj311/uob-summer-project/raw/master/data/feature_matrix.pickle\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/dj311/uob-summer-project/master/data/feature_matrix.pickle [following]\n",
            "--2019-07-30 13:49:12--  https://media.githubusercontent.com/media/dj311/uob-summer-project/master/data/feature_matrix.pickle\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64502734 (62M) [application/octet-stream]\n",
            "Saving to: ‘feature_matrix.pickle’\n",
            "\n",
            "feature_matrix.pick 100%[===================>]  61.51M   190MB/s    in 0.3s    \n",
            "\n",
            "2019-07-30 13:49:14 (190 MB/s) - ‘feature_matrix.pickle’ saved [64502734/64502734]\n",
            "\n",
            "/project/code\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lO9-8NDKk8ja"
      },
      "source": [
        "# Import & Preprocess Dataset\n",
        "\n",
        "First we import the data from the [previous notebook](./adjacency_matrix.ipynb).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uB5QGgAgk8je",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pickle\n",
        "from scipy.sparse import csr_matrix, hstack, vstack\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
        "np.random.seed(1248)\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CGIbzYT0k8jz",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NQwMY_iLk8kC",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('../data/buffer_overflow_data.csv.gz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "76z9869-k8kQ",
        "colab": {}
      },
      "source": [
        "labels = data.copy()\n",
        "del labels['Unnamed: 0']\n",
        "del labels['Unnamed: 0.1']\n",
        "del labels['filename']\n",
        "del labels['code']\n",
        "del labels['flaw']\n",
        "del labels['flaw_loc']\n",
        "labels = labels.drop_duplicates().sort_values('testcase_ID').reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AyqJFOtWk8kg",
        "colab": {}
      },
      "source": [
        "with open(\"../data/adj.pickle\",'rb') as f:\n",
        "    adj = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PHikMdozk8k1",
        "colab": {}
      },
      "source": [
        "adj = adj.rename(columns={0: 'testcase_ID', 1: 'adjacency_matrix'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pIdnRsBjk8k-",
        "colab": {}
      },
      "source": [
        "adj_df = pd.merge(labels, adj, on='testcase_ID')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s-qHa46Vk8lK",
        "colab": {}
      },
      "source": [
        "adj_df = adj_df[['testcase_ID', 'adjacency_matrix', 'bug']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qB06ooxxo--s"
      },
      "source": [
        "Next, find out the maximum size of an adjacency matrix, then convert all matrices to have the same dimension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HNY1UrHJk8lg",
        "colab": {}
      },
      "source": [
        "adj_df['matrix_size'] = adj_df.adjacency_matrix.apply(lambda x: x.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p6zGXUxbk8l1",
        "outputId": "831a0e54-9cee-4346-8286-638c9230e7c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "adj_df['matrix_size'].describe()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    21502.000000\n",
              "mean      2186.138778\n",
              "std       7239.752920\n",
              "min          4.000000\n",
              "25%        349.000000\n",
              "50%        396.000000\n",
              "75%        614.000000\n",
              "max      44401.000000\n",
              "Name: matrix_size, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VlN1pb2SJW2i"
      },
      "source": [
        "So we know that 75% of the dataset has a matrix size <= 614, which is approximately 18000 datapoints. Picking the full dataset would require matrices of dimension 44401x44401 which require 15 gb of memory each. This is isn't feasible, however picking matrices of size 614x614 or less gives a per matrix size of 3.38mb - far more manageable!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JXR174VPKKzR",
        "outputId": "a2ffb974-1e0b-4652-a2b5-f6ea12dcb727",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "matrix_size = 614\n",
        "adj_df = adj_df[adj_df['matrix_size'] <= matrix_size]\n",
        "len(adj_df)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16128"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MCV9Vwupk8mI",
        "colab": {}
      },
      "source": [
        "def matrix_size_corrector(matrix, target_rows, target_columns):\n",
        "    '''Pads matrix with zeros to the desired size'''\n",
        "    \n",
        "    rows, columns = matrix.shape[0], matrix.shape[1]\n",
        "    \n",
        "    row_corrector = csr_matrix((target_rows-rows, columns))\n",
        "    col_corrector = csr_matrix((target_rows, target_columns-columns))\n",
        "\n",
        "    matrix = vstack([matrix, row_corrector])\n",
        "    matrix = hstack([matrix, col_corrector])\n",
        "\n",
        "    matrix = matrix.astype(np.int)\n",
        "    \n",
        "    return matrix "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yI1YFNQMk8mp",
        "colab": {}
      },
      "source": [
        "adj_df['adjacency_matrix'] = adj_df['adjacency_matrix'].apply(lambda m: matrix_size_corrector(m, matrix_size, matrix_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lrFCpTeWNNk",
        "colab_type": "text"
      },
      "source": [
        "Next we load in the feature matrices:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2WAylC-WMu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"../data/feature_matrix.pickle\", \"rb\") as f:\n",
        "    feature_matrix = pickle.load(f)\n",
        "\n",
        "feature_matrix.columns = ['testcase_ID', 'feature_matrix']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcFPwlU2fXgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_features = 55"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G72pK1NiXZz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adj_df = pd.merge(feature_matrix, adj_df, on='testcase_ID')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPKL7-DIe0PC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adj_df['feature_matrix'] = adj_df['feature_matrix'].apply(lambda m: matrix_size_corrector(m, matrix_size, num_features))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zy8qe3IdrKml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testcase_ids = adj_df['testcase_ID'].values\n",
        "adjacency_matrices = adj_df['adjacency_matrix'].values\n",
        "feature_matrices = adj_df['feature_matrix'].values\n",
        "labels = adj_df['bug'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ga6SW3_qpF80"
      },
      "source": [
        "Now we have a dataframe for each testcase with a sparse representation of its AST in the matrix column, each normalised to matrix_size x matrix_size in size.\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W8rFgat6TFnc"
      },
      "source": [
        "Finally, we generate the train and test splits:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxO5J1xySMDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adj_train, adj_test, feat_train, feat_test, labels_train, labels_test = train_test_split(adjacency_matrices, feature_matrices, labels, test_size=0.2, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpXHfAYqeO0a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "8bd23817-7209-4fb0-c4d4-e6ae171d0610"
      },
      "source": [
        "feat_train"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([<614x55 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 341 stored elements in COOrdinate format>,\n",
              "       <614x55 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 271 stored elements in COOrdinate format>,\n",
              "       <614x55 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 57 stored elements in COOrdinate format>,\n",
              "       ...,\n",
              "       <614x55 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 18 stored elements in COOrdinate format>,\n",
              "       <614x55 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 43 stored elements in COOrdinate format>,\n",
              "       <614x55 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 266 stored elements in COOrdinate format>], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yXrUMkzYSgUz"
      },
      "source": [
        "Storing all of these matrices in a dense representation at once might cause memory issues. To avoid this, we write a class which generates dense matrices for each of the training batches. \n",
        "\n",
        "We also perform the element wrapping as part of this process (since we can't perform it on the sparse arrays, I think)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dBPBYHNJxm-D",
        "colab": {}
      },
      "source": [
        "class SparseToDenseGenerator(keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, sparse_adjs, sparse_feats, labels, batch_size):\n",
        "        self.sparse_adjs = sparse_adjs\n",
        "        self.sparse_feats = sparse_feats\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.labels) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, batch_num):\n",
        "        start_index = batch_num * self.batch_size\n",
        "        end_index = (batch_num + 1) * self.batch_size\n",
        "        \n",
        "        batch_sparse_adjs = self.sparse_adjs[start_index:end_index]\n",
        "        batch_sparse_feats = self.sparse_feats[start_index:end_index]\n",
        "        batch_labels = self.labels[start_index:end_index]\n",
        "        \n",
        "        batch_dense_adjs = np.array([sparse_matrix.todense() for sparse_matrix in batch_sparse_adjs])\n",
        "        batch_dense_feats = np.array([sparse_matrix.todense() for sparse_matrix in batch_sparse_feats])\n",
        "        \n",
        "        # TODO: move this somewhere better\n",
        "        # Conv2D requires an extra dimension for \"channels\", so we need to convert our data from\n",
        "        # the shape (batch_size, matrix_rows, matrix_columns)\n",
        "        # to (batch_size, matrix_rows, matrix_columns, 1)\n",
        "        batch_dense_adjs = np.reshape(batch_dense_adjs, batch_dense_adjs.shape + (1, ))\n",
        "        batch_dense_feats = np.reshape(batch_dense_feats, batch_dense_feats.shape + (1, ))\n",
        "\n",
        "        return [batch_dense_adjs, batch_dense_feats], np.array(batch_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nda-Xjsjk8ng"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KqlHfs2Kk8ni",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense, Dropout, Flatten, Reshape, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D, Conv2D, GlobalMaxPooling2D, MaxPooling2D, Convolution2D\n",
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.optimizers import RMSprop, Adadelta, Adam\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kmlCQ77P3itE",
        "outputId": "7c7fa55c-2237-46fd-b6fd-b114f9700b7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch_size = 96\n",
        "epochs = 5\n",
        "num_samples = len(labels)\n",
        "num_features = feature_matrices[0].shape[1]\n",
        "\n",
        "datapoint_shape = (matrix_size, matrix_size, )\n",
        "batch_shape = (batch_size, ) + datapoint_shape\n",
        "\n",
        "steps_per_epoch = int(np.ceil(num_samples/batch_size))\n",
        "\n",
        "kernel_size = (2, 2)\n",
        "strides = max(kernel_size[0] // 3, 1)\n",
        "\n",
        "batch_size, epochs, num_samples, datapoint_shape, batch_shape, steps_per_epoch, kernel_size, strides"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 1, 16128, (614, 614), (32, 614, 614), 504, (2, 2), 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a1aVESBAk8nu",
        "outputId": "7bef2a38-53fc-4853-d2b1-f485c0262c50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 1st: Convolutional Network on Adjacency Matrix\n",
        "adjacency_input = keras.layers.Input(shape=(matrix_size, matrix_size, 1))\n",
        "\n",
        "conv1 = Conv2D(\n",
        "    data_format='channels_last',\n",
        "    input_shape=(matrix_size, matrix_size, 1),\n",
        "    filters=32,\n",
        "    kernel_size=kernel_size,\n",
        "    strides=strides,\n",
        ")(adjacency_input)\n",
        "activation1 = Activation('relu')(conv1)\n",
        "pool1 = MaxPooling2D(kernel_size, padding='same')(activation1)\n",
        "\n",
        "conv2 = Conv2D(\n",
        "    data_format='channels_last',\n",
        "    input_shape=(matrix_size, matrix_size, 1),\n",
        "    filters=32,\n",
        "    kernel_size=kernel_size,\n",
        "    strides=strides,\n",
        ")(pool1)\n",
        "activation2 = Activation('relu')(conv2)\n",
        "pool2 = MaxPooling2D(kernel_size, padding='same')(activation2)\n",
        "\n",
        "conv3 = Conv2D(\n",
        "    data_format='channels_last',\n",
        "    input_shape=(matrix_size, matrix_size, 1),\n",
        "    filters=32,\n",
        "    kernel_size=kernel_size,\n",
        "    strides=strides,\n",
        ")(pool2)\n",
        "activation3 = Activation('relu')(conv3)\n",
        "pool3 = MaxPooling2D(kernel_size, padding='same')(activation3)\n",
        "\n",
        "flatten = Flatten()(pool3)\n",
        "\n",
        "dense1 = Dense(units=32, activation='relu')(flatten)\n",
        "dense2 = Dense(units=32, activation='relu')(dense1)\n",
        "dense3 = Dense(units=32, activation='relu')(dense2)\n",
        "\n",
        "conv_model = keras.models.Model(inputs=adjacency_input, outputs=dense3)\n",
        "\n",
        "# 2nd: Dense, Linear Network on Feature Matrix\n",
        "features_input = keras.layers.Input(shape=(matrix_size, num_features, 1))\n",
        "\n",
        "f_flatten = Flatten(data_format='channels_last')(features_input)\n",
        "\n",
        "f_dense1 = Dense(units=614, activation='relu')(f_flatten)\n",
        "f_dense2 = Dense(units=307, activation='relu')(f_dense1)\n",
        "f_dense3 = Dense(units=150, activation='relu')(f_dense2)\n",
        "f_dense4 = Dense(units=75, activation='relu')(f_dense3)\n",
        "f_dense5 = Dense(units=32, activation='relu')(f_dense4)\n",
        "\n",
        "dense_input = keras.models.Model(inputs = features_input, outputs= f_dense5)\n",
        "\n",
        "# Combine outputs of both networks via a set of dense, linear layers\n",
        "concat = keras.layers.concatenate(inputs=[conv_model.output ,dense_input.output])\n",
        "c_dropout = Dropout(0.2)(concat)\n",
        "c_dense1 =  Dense(units=64, activation='relu')(c_dropout)\n",
        "c_dense2 =  Dense(units=64, activation='relu')(c_dense1)\n",
        "c_dense3 =  Dense(units=64, activation='relu')(c_dense2)\n",
        "\n",
        "# Dropout and final output layer\n",
        "c_output = Dense(units=1, activation='sigmoid')(c_dense3)\n",
        "\n",
        "model = keras.models.Model(inputs=[conv_model.input, dense_input.input], outputs=c_output)\n",
        "\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            (None, 614, 614, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 613, 613, 32) 160         input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 613, 613, 32) 0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 307, 307, 32) 0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 306, 306, 32) 4128        max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 306, 306, 32) 0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling2D) (None, 153, 153, 32) 0           activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 152, 152, 32) 4128        max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           (None, 614, 55, 1)   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 152, 152, 32) 0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_10 (Flatten)            (None, 33770)        0           input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling2D) (None, 76, 76, 32)   0           activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_48 (Dense)                (None, 614)          20735394    flatten_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_9 (Flatten)             (None, 184832)       0           max_pooling2d_15[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_49 (Dense)                (None, 307)          188805      dense_48[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_45 (Dense)                (None, 32)           5914656     flatten_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_50 (Dense)                (None, 150)          46200       dense_49[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_46 (Dense)                (None, 32)           1056        dense_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_51 (Dense)                (None, 75)           11325       dense_50[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_47 (Dense)                (None, 32)           1056        dense_46[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_52 (Dense)                (None, 32)           2432        dense_51[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 64)           0           dense_47[0][0]                   \n",
            "                                                                 dense_52[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 64)           0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_53 (Dense)                (None, 64)           4160        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_54 (Dense)                (None, 64)           4160        dense_53[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_55 (Dense)                (None, 64)           4160        dense_54[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_56 (Dense)                (None, 1)            65          dense_55[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 26,921,885\n",
            "Trainable params: 26,921,885\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gAErQWeyk8nz",
        "outputId": "c9b5c166-4071-479b-f737-53871d514622",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "training_batch_generator = SparseToDenseGenerator(adj_train, feat_train, labels_train, batch_size)\n",
        "\n",
        "model.fit_generator(\n",
        "    generator=training_batch_generator,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=steps_per_epoch\n",
        ")"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "504/504 [==============================] - 2456s 5s/step - loss: 0.3877 - acc: 0.7995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f76ca66e470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wk-asGoMk8oK",
        "colab": {}
      },
      "source": [
        "with open('../data/adjacency-feature-matrix-model-binary.pickle', 'wb') as f:\n",
        "    pickle.dump(model,f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w3476EyA3g-V"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQcagc2HK0c3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = None\n",
        "with open('../data/adjacency-feature-matrix-model-binary.pickle', 'rb') as f:\n",
        "    model = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nobNI0B1k8oP",
        "scrolled": true,
        "outputId": "2d5e2b97-3bd2-40f0-f6d2-056b9079a9f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_batch_generator = SparseToDenseGenerator(adj_test, feat_test, labels_test, batch_size)\n",
        "\n",
        "model.evaluate_generator(\n",
        "    generator=test_batch_generator,\n",
        ")"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.29026095635889854, 0.9009455898217944]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vnHI_fjlk8ob",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "import matplotlib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4bFyChZOi0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SparseToDensePredictGenerator(keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, sparse_adjs, sparse_feats, batch_size):\n",
        "        self.sparse_adjs = sparse_adjs\n",
        "        self.sparse_feats = sparse_feats\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.sparse_feats) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, batch_num):\n",
        "        start_index = batch_num * self.batch_size\n",
        "        end_index = (batch_num + 1) * self.batch_size\n",
        "        \n",
        "        batch_sparse_adjs = self.sparse_adjs[start_index:end_index]\n",
        "        batch_sparse_feats = self.sparse_feats[start_index:end_index]\n",
        "        \n",
        "        batch_dense_adjs = np.array([sparse_matrix.todense() for sparse_matrix in batch_sparse_adjs])\n",
        "        batch_dense_feats = np.array([sparse_matrix.todense() for sparse_matrix in batch_sparse_feats])\n",
        "        \n",
        "        # TODO: move this somewhere better\n",
        "        # Conv2D requires an extra dimension for \"channels\", so we need to convert our data from\n",
        "        # the shape (batch_size, matrix_rows, matrix_columns)\n",
        "        # to (batch_size, matrix_rows, matrix_columns, 1)\n",
        "        batch_dense_adjs = np.reshape(batch_dense_adjs, batch_dense_adjs.shape + (1, ))\n",
        "        batch_dense_feats = np.reshape(batch_dense_feats, batch_dense_feats.shape + (1, ))\n",
        "\n",
        "        return [batch_dense_adjs, batch_dense_feats]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5AJ9ozp5k8og",
        "colab": {}
      },
      "source": [
        "predict_batch_generator = SparseToDensePredictGenerator(adj_test, feat_test, batch_size)\n",
        "y_predict = model.predict_generator(predict_batch_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gh6M9qH-k8ok",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xrvhYYmFk8oo",
        "colab": {}
      },
      "source": [
        "confusion_matrix = pd.DataFrame(\n",
        "    data=metrics.confusion_matrix(y_test, np.rint(y_predict)),\n",
        ")\n",
        "\n",
        "confusion_figure, confusion_axes = matplotlib.pyplot.subplots()\n",
        "confusion_figure.set_size_inches(15, 12)\n",
        "confusion_axes.set_title(\n",
        "    'Confusion matrix showing the frequency of \\n'\n",
        "    'correct and incorrect bug classification predictions.'\n",
        "    '\\n\\n'  # hack to avoid overlap with x-axis labels below\n",
        ")\n",
        "confusion_axes.xaxis.tick_top()  # move x-axis labels to top of matrix\n",
        "_ = sns.heatmap(\n",
        "    confusion_matrix,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=sns.color_palette(\"Blues\"),\n",
        "    vmin=0,\n",
        "    ax=confusion_axes,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yatQ4RKhP2H0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.argmax(y_test.astype(int)), np.argmax(np.rint(y_predict)),"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SFlZwTBIk8o8",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "fpr_keras, tpr_keras, thresholds_keras = roc_curve(\n",
        "    y_test.astype(int),\n",
        "    np.rint(y_predict),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a8_7LWSmk8pI",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import auc\n",
        "import matplotlib.pyplot as plt\n",
        "auc_keras = auc(fpr_keras, tpr_keras)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mM9vPPIGk8pO",
        "colab": {}
      },
      "source": [
        "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIxU3yLeZqk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tn, fp, fn, tp = metrics.confusion_matrix(\n",
        "    y_test.astype(int), \n",
        "    np.rint(y_predict)\n",
        ").flatten().tolist()\n",
        "\n",
        "fpr_nn = fp/(fp+tp)\n",
        "fnr_nn = fn/(fn+tn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Irias0wiQ5uS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fpr_nn, fnr_nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srThRIL4rPVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}