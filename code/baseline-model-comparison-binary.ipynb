{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Collecting scikit-learn (from sklearn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/a4/a48bd4b0d15395362b561df7e7247de87291105eb736a3b2aaffebf437b9/scikit_learn-0.21.2-cp37-cp37m-manylinux1_x86_64.whl (6.7MB)\n",
      "\u001b[K     |████████████████████████████████| 6.7MB 3.2MB/s eta 0:00:01     |███                             | 604kB 3.2MB/s eta 0:00:02     |████████▊                       | 1.8MB 3.2MB/s eta 0:00:02     |██████████████████              | 3.7MB 3.2MB/s eta 0:00:01     |█████████████████████▍          | 4.5MB 3.2MB/s eta 0:00:01     |███████████████████████▎        | 4.9MB 3.2MB/s eta 0:00:01     |█████████████████████████▋      | 5.3MB 3.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.16.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (0.13.0)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "Successfully built sklearn\n",
      "Installing collected packages: scikit-learn, sklearn\n",
      "Successfully installed scikit-learn-0.21.2 sklearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop, Adadelta, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/buffer_overflow_data.csv.gz')\n",
    "labels = data.copy()\n",
    "del labels['Unnamed: 0']\n",
    "del labels['Unnamed: 0.1']\n",
    "del labels['filename']\n",
    "del labels['code']\n",
    "del labels['flaw']\n",
    "del labels['flaw_loc']\n",
    "labels = labels.drop_duplicates().sort_values('testcase_ID').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(\"../data/buffer_overflow_graph_embeddings.csv.gz\")\n",
    "x['testcase_ID'] = x['type']\n",
    "del x['type']\n",
    "x = x.sort_values(\"testcase_ID\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = labels['bug']\n",
    "x = x.drop('testcase_ID', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.5, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Neural tutorial](https://towardsdatascience.com/neural-networks-from-scratch-easy-vs-hard-b26ddc2e89c7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "with open('../data/baseline-model-binary','rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10751/10751 [==============================] - 0s 36us/step\n"
     ]
    }
   ],
   "source": [
    "nn_evaluate = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_score = nn_evaluate[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change Confusion Matrix Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-24a9dfc74c22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m confusion_matrix = pd.DataFrame(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[0mconfusion_figure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconfusion_figure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_size_inches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "confusion_matrix = pd.DataFrame(\n",
    "    data=metrics.confusion_matrix((y_test.values+0).argmax(axis=1), y_predict.argmax(axis=1)), \n",
    ")\n",
    "confusion_figure, confusion_axes = matplotlib.pyplot.subplots()\n",
    "confusion_figure.set_size_inches(15, 12)\n",
    "confusion_axes.set_title(\n",
    "    'Confusion matrix showing the frequency of \\n'\n",
    "    'correct and incorrect bug classification predictions.'\n",
    "    '\\n\\n'  # hack to avoid overlap with x-axis labels below\n",
    ")\n",
    "sns.heatmap(confusion_matrix, norm=LogNorm(confusion_matrix.min().min(),confusion_matrix.max().max()),\n",
    "            vmin = 0.001, vmax=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=1, n_jobs=None,\n",
       "                      oob_score=False, random_state=42, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.016853458189709514"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = pd.DataFrame(rf.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort Visualisation Below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'visualisation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-f35822eaeadf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvisualisation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcve_predict_table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'visualisation'"
     ]
    }
   ],
   "source": [
    "# from keras.utils import to_categorical\n",
    "\n",
    "# from visualisation import cve_predict_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example_script = x_test.iloc[0,]\n",
    "#example_label = y_test.iloc[0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-8356f4603995>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcve_predict_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_script\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/project/code/visualisation.py\u001b[0m in \u001b[0;36mcve_predict_table\u001b[0;34m(df, model, script, bug_label)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mbug_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbug_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mbug_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbug_label\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "#cve_predict_table(data, rf, example_script, example_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "oneknn = KNeighborsClassifier(n_neighbors=1,weights = 'distance')\n",
    "oneknn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneknn_score=oneknn.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8069946981676123"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneknn_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2NN returns the same as one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "threeknn = KNeighborsClassifier(n_neighbors=3,weights = 'distance')\n",
    "threeknn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "threeknn_score=threeknn.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7979722816482188"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threeknn_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred_gnb = gnb.fit(x_train, y_train).predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 10751 points : 4348\n",
      "Accuracy 0.5955725048832667\n"
     ]
    }
   ],
   "source": [
    "total_error = (y_test != y_pred_gnb).sum()\n",
    "\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "       % (x_test.shape[0],total_error))\n",
    "print(\"Accuracy \" + str(1- (total_error/x_test.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_score = 1- (total_error/x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf_svm = svm.SVC(kernel = 'poly', gamma='scale')\n",
    "clf_svm.fit(x_train, y_train)  \n",
    "\n",
    "y_pred_svm = clf_svm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 10751 points : 1334\n",
      "Accuracy 0.8759185192075156\n"
     ]
    }
   ],
   "source": [
    "total_error = (y_test != y_pred_svm).sum()\n",
    "\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "       % (x_test.shape[0],total_error))\n",
    "print(\"Accuracy \" + str(1- (total_error/x_test.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_score = 1- (total_error/x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8430843642451865\n"
     ]
    }
   ],
   "source": [
    "y_pred_lr = logreg.predict(x_test)\n",
    "print('Accuracy ' + str(logreg.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_accuracy = logreg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_ab = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "clf_ab.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ab = clf_ab.predict(x_test)\n",
    "# y_pred = y_pred.reshape(-1,1)\n",
    "# y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 10751 points : 2223\n",
      "Accuracy 0.7932285368802903\n"
     ]
    }
   ],
   "source": [
    "total_error = (y_test != y_pred_ab).sum()\n",
    "\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "       % (x_test.shape[0],total_error))\n",
    "print(\"Accuracy \" + str(1- (total_error/x_test.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_accuracy = 1- (total_error/x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/24/5fe7237b2eca13ee0cfb100bec8c23f4e69ce9df852a64b0493d49dae4e0/xgboost-0.90-py2.py3-none-manylinux1_x86_64.whl (142.8MB)\n",
      "\u001b[K     |████████████████████████████████| 142.8MB 100kB/s eta 0:00:012  |▊                               | 3.4MB 2.6MB/s eta 0:00:54     |█▍                              | 6.1MB 2.6MB/s eta 0:00:53     |█▋                              | 7.4MB 7.0MB/s eta 0:00:20     |█▊                              | 7.7MB 7.0MB/s eta 0:00:20     |██                              | 9.2MB 7.0MB/s eta 0:00:20     |██▏                             | 9.9MB 7.0MB/s eta 0:00:19     |██▋                             | 11.5MB 7.0MB/s eta 0:00:19     |██▊                             | 12.0MB 7.0MB/s eta 0:00:19     |██▉                             | 12.9MB 6.7MB/s eta 0:00:20     |███                             | 13.4MB 6.7MB/s eta 0:00:20     |███▏                            | 14.1MB 6.7MB/s eta 0:00:20     |████▍                           | 19.7MB 6.7MB/s eta 0:00:19     |████▌                           | 20.2MB 6.7MB/s eta 0:00:19     |████▋                           | 20.5MB 6.7MB/s eta 0:00:19     |████▊                           | 20.9MB 6.7MB/s eta 0:00:19     |█████                           | 22.2MB 6.7MB/s eta 0:00:18     |█████▍                          | 23.9MB 6.7MB/s eta 0:00:18     |█████▌                          | 24.6MB 10.3MB/s eta 0:00:12     |██████                          | 26.7MB 10.3MB/s eta 0:00:12     |██████▌                         | 29.2MB 10.3MB/s eta 0:00:12     |██████▊                         | 30.0MB 1.8MB/s eta 0:01:03     |███████                         | 31.4MB 1.8MB/s eta 0:01:02     |███████▉                        | 35.1MB 1.8MB/s eta 0:01:00     |████████                        | 36.1MB 4.6MB/s eta 0:00:23     |████████▌                       | 37.9MB 4.6MB/s eta 0:00:23     |████████▊                       | 38.9MB 4.6MB/s eta 0:00:23     |████████▊                       | 39.1MB 4.6MB/s eta 0:00:23     |█████████                       | 40.0MB 4.6MB/s eta 0:00:23     |█████████▍                      | 41.8MB 10.4MB/s eta 0:00:10     |█████████▊                      | 43.4MB 10.4MB/s eta 0:00:10     |██████████▍                     | 46.5MB 10.4MB/s eta 0:00:10     |██████████▌                     | 46.9MB 10.4MB/s eta 0:00:10     |██████████▉                     | 48.5MB 6.3MB/s eta 0:00:16     |███████████                     | 49.6MB 6.3MB/s eta 0:00:15     |███████████▍                    | 51.0MB 6.3MB/s eta 0:00:15     |███████████▌                    | 51.4MB 6.3MB/s eta 0:00:15     |███████████▊                    | 52.3MB 6.3MB/s eta 0:00:15     |████████████▏                   | 54.5MB 5.8MB/s eta 0:00:16     |████████████▉                   | 57.4MB 5.8MB/s eta 0:00:15     |█████████████                   | 58.3MB 4.1MB/s eta 0:00:21     |██████████████▍                 | 64.3MB 4.1MB/s eta 0:00:20     |███████████████                 | 67.0MB 3.9MB/s eta 0:00:20     |███████████████▏                | 67.9MB 3.9MB/s eta 0:00:20     |███████████████▎                | 68.2MB 3.9MB/s eta 0:00:20     |███████████████▋                | 69.5MB 3.9MB/s eta 0:00:19     |███████████████▊                | 70.0MB 3.9MB/s eta 0:00:19     |███████████████▊                | 70.4MB 3.9MB/s eta 0:00:19     |████████████████                | 71.1MB 5.8MB/s eta 0:00:13     |████████████████                | 71.5MB 5.8MB/s eta 0:00:13     |████████████████                | 71.9MB 5.8MB/s eta 0:00:13     |████████████████▍               | 73.1MB 5.8MB/s eta 0:00:13     |████████████████▊               | 74.4MB 5.8MB/s eta 0:00:12     |██████████████████▌             | 82.8MB 1.7MB/s eta 0:00:35     |██████████████████▋             | 83.1MB 1.7MB/s eta 0:00:35     |███████████████████▏            | 85.4MB 6.7MB/s eta 0:00:09     |███████████████████▎            | 85.8MB 6.7MB/s eta 0:00:09     |███████████████████▎            | 86.2MB 6.7MB/s eta 0:00:09     |████████████████████            | 89.5MB 6.0MB/s eta 0:00:09     |████████████████████▍           | 91.2MB 6.0MB/s eta 0:00:09     |█████████████████████           | 93.5MB 6.0MB/s eta 0:00:09     |█████████████████████▋          | 96.5MB 4.9MB/s eta 0:00:10     |██████████████████████          | 98.4MB 4.9MB/s eta 0:00:09     |██████████████████████▎         | 99.3MB 4.9MB/s eta 0:00:09     |██████████████████████▎         | 99.4MB 4.9MB/s eta 0:00:09     |██████████████████████▋         | 100.9MB 4.9MB/s eta 0:00:09     |███████████████████████▎        | 103.9MB 5.2MB/s eta 0:00:08     |███████████████████████▍        | 104.5MB 5.2MB/s eta 0:00:08     |███████████████████████▉        | 106.3MB 5.2MB/s eta 0:00:07     |████████████████████████        | 107.3MB 5.2MB/s eta 0:00:07     |████████████████████████▌       | 109.3MB 7.1MB/s eta 0:00:05     |████████████████████████▋       | 109.9MB 7.1MB/s eta 0:00:05     |█████████████████████████       | 111.4MB 7.1MB/s eta 0:00:05     |█████████████████████████▏      | 112.2MB 7.1MB/s eta 0:00:05     |█████████████████████████▏      | 112.5MB 7.1MB/s eta 0:00:05     |█████████████████████████▌      | 113.9MB 7.1MB/s eta 0:00:05     |█████████████████████████▋      | 114.2MB 7.1MB/s eta 0:00:05     |██████████████████████████▍     | 117.8MB 5.0MB/s eta 0:00:05     |██████████████████████████▌     | 118.5MB 5.0MB/s eta 0:00:05     |██████████████████████████▋     | 118.8MB 5.0MB/s eta 0:00:05     |███████████████████████████▎    | 121.6MB 2.6MB/s eta 0:00:09     |███████████████████████████▋    | 123.1MB 2.6MB/s eta 0:00:08     |████████████████████████████    | 125.1MB 2.6MB/s eta 0:00:07     |████████████████████████████▎   | 126.2MB 2.6MB/s eta 0:00:07     |████████████████████████████▊   | 128.3MB 10.0MB/s eta 0:00:02     |█████████████████████████████▊  | 132.7MB 10.0MB/s eta 0:00:02     |█████████████████████████████▉  | 133.0MB 8.3MB/s eta 0:00:02     |█████████████████████████████▉  | 133.3MB 8.3MB/s eta 0:00:02     |██████████████████████████████  | 133.8MB 8.3MB/s eta 0:00:02     |██████████████████████████████  | 134.2MB 8.3MB/s eta 0:00:02     |███████████████████████████████ | 138.3MB 8.3MB/s eta 0:00:01     |████████████████████████████████| 142.4MB 7.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.16.4)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.90\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6984466561250117"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "model_xgb=xgb.XGBClassifier(random_state=1,learning_rate=0.01)\n",
    "model_xgb.fit(x_train, y_train)\n",
    "model_xgb.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = model_xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 10751 points : 3242\n",
      "Accuracy 0.6984466561250116\n"
     ]
    }
   ],
   "source": [
    "total_error = (y_test != y_pred_xgb).sum()\n",
    "\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "       % (x_test.shape[0],total_error))\n",
    "print(\"Accuracy \" + str(1- (total_error/x_test.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_accuracy = 1- (total_error/x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'Model': ['Neural Network', 'Random Forest', '1 Nearest Neighbour', '3 Nearest Neighbours', 'Gaussian Naive Bayes', 'SVM', 'Logistic Regression', 'AdaBoost', 'XGBoost'], 'Accuracy' : [nn_score, rf_accuracy, oneknn_score, threeknn_score, gnb_score, svm_score, logreg_accuracy, ab_accuracy, xgb_accuracy]}\n",
    "accuracy_table = pd.DataFrame(data = results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.912845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.875919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.843084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 Nearest Neighbour</td>\n",
       "      <td>0.806995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3 Nearest Neighbours</td>\n",
       "      <td>0.797972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.793229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.745791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.698447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.595573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy\n",
       "0        Neural Network  0.912845\n",
       "5                   SVM  0.875919\n",
       "6   Logistic Regression  0.843084\n",
       "2   1 Nearest Neighbour  0.806995\n",
       "3  3 Nearest Neighbours  0.797972\n",
       "7              AdaBoost  0.793229\n",
       "1         Random Forest  0.745791\n",
       "8               XGBoost  0.698447\n",
       "4  Gaussian Naive Bayes  0.595573"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_table.sort_values(by = ['Accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vecstack\n",
      "  Downloading https://files.pythonhosted.org/packages/d9/1d/7665736f10f3e15af9d51b4e73c16c8ea798e339f6bf4eadfa1dee77c672/vecstack-0.3.0.tar.gz\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from vecstack) (1.16.4)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from vecstack) (0.21.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from vecstack) (1.3.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->vecstack) (0.13.0)\n",
      "Building wheels for collected packages: vecstack\n",
      "  Building wheel for vecstack (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/35/6d/ca/bce17942bcf7c267b13c97c9c95e2f0ecf0b42160e6074f448\n",
      "Successfully built vecstack\n",
      "Installing collected packages: vecstack\n",
      "Successfully installed vecstack-0.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install vecstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from vecstack import stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [clf_svm, logreg, oneknn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [3]\n",
      "\n",
      "model  0:     [SVC]\n",
      "    fold  0:  [0.86649312]\n",
      "    fold  1:  [0.86607143]\n",
      "    fold  2:  [0.87272051]\n",
      "    fold  3:  [0.85746185]\n",
      "    ----\n",
      "    MEAN:     [0.86568673] + [0.00542957]\n",
      "    FULL:     [0.86568691]\n",
      "\n",
      "model  1:     [LogisticRegression]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  0:  [0.85050205]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  1:  [0.83928571]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  2:  [0.82471157]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  3:  [0.82954968]\n",
      "    ----\n",
      "    MEAN:     [0.83601225] + [0.00987598]\n",
      "    FULL:     [0.83601525]\n",
      "\n",
      "model  2:     [KNeighborsClassifier]\n",
      "    fold  0:  [0.79471923]\n",
      "    fold  1:  [0.79055060]\n",
      "    fold  2:  [0.79233346]\n",
      "    fold  3:  [0.80089319]\n",
      "    ----\n",
      "    MEAN:     [0.79462412] + [0.00390996]\n",
      "    FULL:     [0.79462376]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "S_train, S_test = stacking(models,                   \n",
    "                           x_train, y_train, x_test,   \n",
    "                           regression=False, \n",
    "     \n",
    "                           mode='oof_pred_bag', \n",
    "       \n",
    "                           needs_proba=False,\n",
    "         \n",
    "                           save_dir=None, \n",
    "            \n",
    "                           metric=accuracy_score, \n",
    "    \n",
    "                           n_folds=4, \n",
    "                 \n",
    "                           stratified=True,\n",
    "            \n",
    "                           shuffle=True,  \n",
    "            \n",
    "                           random_state=0,    \n",
    "         \n",
    "                           verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_two = clf_svm.fit(S_train, y_train)\n",
    "y_pred_stack = level_two.predict(S_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction score: [0.89154497]\n"
     ]
    }
   ],
   "source": [
    "print('Final prediction score: [%.8f]' % accuracy_score(y_test, y_pred_stack))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
